import cv2
import numpy as np
import os
import json
import time
from paddleocr import PaddleOCR

# ------------------- ÏÑ§Ï†ï -------------------
# Ïπ¥Î©îÎùº Ïû•Ïπò Î≤àÌò∏ (Îß§ÏßÅ ÎÑòÎ≤Ñ)
CAMERA_ID = 0      # 0 or 4 ÏÇ¨Ïö© Í∞ÄÎä•
FRAME_WIDTH = 960
FRAME_HEIGHT = 540

# OCR / Ï∂úÎ†• ÏÑ§Ï†ï
OCR_CONF_THRESH = 0.5
OUTPUT_DIR = os.path.join("..", "assets", "samples")
os.makedirs(OUTPUT_DIR, exist_ok=True)
OUTPUT_IMG_PATH = os.path.join(OUTPUT_DIR, "test_camera.jpeg")
OUTPUT_JSON_PATH = os.path.join(OUTPUT_DIR, "test_camera_result.json")

# PaddleOCR Ï¥àÍ∏∞Ìôî
ocr = PaddleOCR(lang="en")

# ------------------- OCR Î≥ëÌï© Ìï®Ïàò -------------------
def merge_words_with_boxes(image, ocr_result, y_thresh=20, x_gap_thresh=30):
    lines = []
    for box_info in ocr_result:
        box, (text, conf) = box_info
        x_coords = [p[0] for p in box]
        y_coords = [p[1] for p in box]
        cx, cy = np.mean(x_coords), np.mean(y_coords)
        lines.append({
            "text": text.strip(),
            "conf": float(conf),
            "cx": cx,
            "cy": cy,
            "x_min": min(x_coords),
            "x_max": max(x_coords),
            "box": np.array(box).astype(int).tolist()
        })

    if not lines:
        return [], image

    # YÏ¢åÌëú Í∏∞Ï§Ä Ï†ïÎ†¨
    lines.sort(key=lambda t: (t["cy"], t["cx"]))

    grouped_lines = []
    current_line = [lines[0]]
    for i in range(1, len(lines)):
        if abs(lines[i]["cy"] - current_line[-1]["cy"]) <= y_thresh:
            current_line.append(lines[i])
        else:
            grouped_lines.append(current_line)
            current_line = [lines[i]]
    grouped_lines.append(current_line)

    merged_results = []
    font = cv2.FONT_HERSHEY_SIMPLEX
    color_list = [
        (0, 255, 0), (255, 255, 0), (0, 255, 255),
        (255, 128, 0), (255, 0, 255), (0, 128, 255)
    ]

    for line_idx, line in enumerate(grouped_lines, start=1):
        line.sort(key=lambda t: t["x_min"])
        merged_line = []
        current_word = line[0]["text"]

        for i in range(1, len(line)):
            gap = line[i]["x_min"] - line[i - 1]["x_max"]
            if gap < x_gap_thresh:
                current_word += " " + line[i]["text"]
            else:
                merged_line.append(current_word)
                current_word = line[i]["text"]
        merged_line.append(current_word)
        merged_text = " ".join(merged_line)

        # ÏãúÍ∞ÅÌôî
        for word in line:
            pts = np.array(word["box"], np.int32)
            cv2.polylines(image, [pts], isClosed=True,
                          color=color_list[line_idx % len(color_list)], thickness=2)

        y_pos = int(line[0]["cy"]) - 10
        cv2.putText(image, f"{line_idx}. {merged_text}",
                    (int(line[0]["x_min"]), y_pos),
                    font, 0.7, (0, 0, 255), 2)

        merged_results.append({
            "line_index": line_idx,
            "text": merged_text,
            "avg_conf": float(np.mean([w["conf"] for w in line]))
        })

    return merged_results, image


# ------------------- Î©îÏù∏ Ïπ¥Î©îÎùº Î£®ÌîÑ -------------------
def main():
    print(f"üé• Ïπ¥Î©îÎùº {CAMERA_ID} Î≤à Ïû•Ïπò ÏãúÏûë Ï§ë...")
    cap = cv2.VideoCapture(CAMERA_ID)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)

    if not cap.isOpened():
        print(f"‚ùå Ïπ¥Î©îÎùº {CAMERA_ID}Î•º Ïó¥ Ïàò ÏóÜÏäµÎãàÎã§.")
        return

    print("‚úÖ Ïã§ÏãúÍ∞Ñ OCR ÏãúÏûë (Ï∫°Ï≤ò: SPACE / Ï¢ÖÎ£å: Q)")
    font = cv2.FONT_HERSHEY_SIMPLEX

    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ö†Ô∏è ÌîÑÎ†àÏûÑÏùÑ ÏùΩÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
            break

        # ÌëúÏãúÏö©
        display = frame.copy()
        cv2.putText(display, f"Camera {CAMERA_ID} | Press [SPACE] to OCR, [Q] to Quit",
                    (10, 30), font, 0.6, (255, 255, 255), 2)
        cv2.imshow("Camera OCR Live", display)

        key = cv2.waitKey(1) & 0xFF
        if key == ord("q"):
            break

        # OCR Ï∫°Ï≤ò
        if key == 32:  # Spacebar
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            print(f"\nüì∏ Ïù¥ÎØ∏ÏßÄ Ï∫°Ï≤ò ({timestamp}) ‚Üí OCR ÏãúÏûë Ï§ë...")
            frame_copy = frame.copy()

            ocr_result = ocr.ocr(frame_copy, cls=False)
            merged_results, vis_img = merge_words_with_boxes(frame_copy, ocr_result[0])

            # Í≤∞Í≥º Ï†ÄÏû•
            img_out = OUTPUT_IMG_PATH.replace("test_camera", f"capture_{timestamp}")
            json_out = OUTPUT_JSON_PATH.replace("test_camera", f"capture_{timestamp}")
            cv2.imwrite(img_out, vis_img)
            with open(json_out, "w", encoding="utf-8") as f:
                json.dump(merged_results, f, ensure_ascii=False, indent=4)

            print(f"‚úÖ Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å:\n- Ïù¥ÎØ∏ÏßÄ: {img_out}\n- JSON: {json_out}")

            # ÌôîÎ©¥Ïóê OCR Í≤∞Í≥º ÌëúÏãú
            for idx, line in enumerate(merged_results, start=1):
                print(f"{idx}. {line['text']} (Ï†ïÌôïÎèÑ: {line['avg_conf']:.2f})")

    cap.release()
    cv2.destroyAllWindows()
    print("üü¢ Ï¢ÖÎ£åÎêòÏóàÏäµÎãàÎã§.")


# ------------------- Ïã§Ìñâ -------------------
if __name__ == "__main__":
    main()

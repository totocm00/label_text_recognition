import cv2
import numpy as np
import os
import json
from paddleocr import PaddleOCR

# ------------------- ì„¤ì • -------------------
ocr = PaddleOCR(lang='en')
IMG_PATH = "test.jpg"

# ì¶œë ¥ í´ë” ë° íŒŒì¼ ê²½ë¡œ
OUTPUT_DIR = os.path.join("..", "assets", "samples")
os.makedirs(OUTPUT_DIR, exist_ok=True)
OUTPUT_IMG_PATH = os.path.join(OUTPUT_DIR, "test.jpeg")
OUTPUT_JSON_PATH = os.path.join(OUTPUT_DIR, "test_result.json")


# ------------------- í•¨ìˆ˜ ì •ì˜ -------------------
def merge_words_with_boxes(image, ocr_result, y_thresh=20, x_gap_thresh=30):
    """
    OCR ê²°ê³¼ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ì •ë ¬ ë° ë³‘í•©í•˜ê³  ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±
    """
    lines = []
    for box_info in ocr_result:
        box, (text, conf) = box_info
        x_coords = [p[0] for p in box]
        y_coords = [p[1] for p in box]
        cx, cy = np.mean(x_coords), np.mean(y_coords)
        lines.append({
            "text": text.strip(),
            "conf": float(conf),
            "cx": cx,
            "cy": cy,
            "x_min": min(x_coords),
            "x_max": max(x_coords),
            "box": np.array(box).astype(int).tolist()
        })

    # Yì¢Œí‘œ ê¸°ì¤€ ì •ë ¬
    lines.sort(key=lambda t: (t["cy"], t["cx"]))

    # ì¤„ ê·¸ë£¹í™”
    grouped_lines = []
    current_line = [lines[0]]
    for i in range(1, len(lines)):
        if abs(lines[i]["cy"] - current_line[-1]["cy"]) <= y_thresh:
            current_line.append(lines[i])
        else:
            grouped_lines.append(current_line)
            current_line = [lines[i]]
    grouped_lines.append(current_line)

    merged_results = []
    font = cv2.FONT_HERSHEY_SIMPLEX
    color_list = [
        (0, 255, 0), (255, 255, 0), (0, 255, 255),
        (255, 128, 0), (255, 0, 255), (0, 128, 255)
    ]

    # ì¤„ ë‹¨ìœ„ ë³‘í•© ë° ì‹œê°í™”
    for line_idx, line in enumerate(grouped_lines, start=1):
        line.sort(key=lambda t: t["x_min"])
        merged_line = []
        current_word = line[0]["text"]

        for i in range(1, len(line)):
            gap = line[i]["x_min"] - line[i - 1]["x_max"]
            if gap < x_gap_thresh:
                current_word += " " + line[i]["text"]
            else:
                merged_line.append(current_word)
                current_word = line[i]["text"]
        merged_line.append(current_word)
        merged_text = " ".join(merged_line)

        # ì‹œê°í™”
        for word in line:
            pts = np.array(word["box"], np.int32)
            cv2.polylines(image, [pts], isClosed=True,
                          color=color_list[line_idx % len(color_list)], thickness=2)

        y_pos = int(line[0]["cy"]) - 10
        cv2.putText(image, f"{line_idx}. {merged_text}",
                    (int(line[0]["x_min"]), y_pos),
                    font, 0.7, (0, 0, 255), 2)

        # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
        merged_results.append({
            "line_index": line_idx,
            "text": merged_text,
            "avg_conf": float(np.mean([w["conf"] for w in line]))
        })

    return merged_results, image


# ------------------- ì‹¤í–‰ -------------------
if __name__ == "__main__":
    print("ğŸ” OCR ë¶„ì„ ì‹œì‘...")

    img = cv2.imread(IMG_PATH)
    result = ocr.ocr(IMG_PATH, cls=False)

    merged_results, vis_img = merge_words_with_boxes(img, result[0])

    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ§© ì¸ì‹ ìˆœì„œëŒ€ë¡œ ì •ë ¬ëœ í…ìŠ¤íŠ¸:")
    for line in merged_results:
        print(f"{line['line_index']}. {line['text']} (ì •í™•ë„: {line['avg_conf']:.2f})")

    # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥
    cv2.imwrite(OUTPUT_IMG_PATH, vis_img)
    print(f"\nâœ… ì‹œê°í™” ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {OUTPUT_IMG_PATH}")

    # JSON ì €ì¥
    with open(OUTPUT_JSON_PATH, "w", encoding="utf-8") as f:
        json.dump(merged_results, f, ensure_ascii=False, indent=4)
    print(f"âœ… JSON ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {OUTPUT_JSON_PATH}")
